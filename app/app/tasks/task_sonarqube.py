from langchain.prompts import PromptTemplate
# from app.tools.tools_sonar_analyzis import ToolSonarqube
from openai import OpenAI
import json

class TaskSonarqube:
    
    def __init__(self,ollama_url, metric_json, sonar_token, repository_name, org_or_user):
        self.ollama_url = ollama_url
        self.metric_json = metric_json
        self.sonar_token = sonar_token
        self.repository_name = repository_name
        self.org_or_user = org_or_user
    
    def prompt_system(self):
        
        template = """
        You are a senior software engineer.
        Your skill is to analyze metrics using the Sonarqube tool to provide valuable insights on areas that need improvement in a given application.
        The metrics available belong to the {domain_name} domain. Please refer to the domain description to understand the context of the metrics: {domain_description}\n.
        """
        
        prompt_template = PromptTemplate.from_template(template)
        return prompt_template
    
    def prompt_user(self):
        template = """
        The [Description] section contains descriptions of each metric.
        The [Metrics] section contains the metrics generated by the tool for a particular repository.
            
        [Description]
        {description}\n\n
            
        [Metrics]
        {metrics}\n
        """
        
        prompt_template = PromptTemplate.from_template(template)
        return prompt_template
    
    def get_domain(self):
        with open(self.metric_json, 'r') as arquivo:
            json_data = json.load(arquivo)
            
            domain_name = json_data['Domain']
            domain_description = json_data['Context']

        return domain_name,domain_description
    
    def get_keys_and_descriptions(self):
        with open(self.metric_json, 'r') as arquivo:
            json_data = json.load(arquivo)
            metrics = json_data["Metrics"]
            result = ""
            for metric in metrics:
                result += f"- {metric['key']}: {metric['description']}\n"
        return result
    
    def get_metrics(self, sonar_analysis: bool=False):
        sonar = ToolSonarqube(sonar_token=self.sonar_token,project_name=self.repository_name,
                         github_url=f"https://github.com/{self.org_or_user}/{self.repository_name}")
        evaluation_sonar = sonar.make_evaluation(self.metric_json, sonar_analysis=sonar_analysis)

        result = ""
        for evaluation in evaluation_sonar:
            result += f"- {evaluation}\n"
        
        return result
    
    def create_chat(self):
        client = OpenAI(base_url=f"{self.ollama_url}", api_key="not-needed")
        domain_name, domain_description = self.get_domain()
        metrics_description = self.get_keys_and_descriptions()
        metrics_results = self.get_metrics(sonar_analysis=True)
        
        print(metrics_results)
                
        completion = client.chat.completions.create(
            model="llama2",
            messages=[
                {"role": "system", "content": self.prompt_system().format(domain_name=domain_name, 
                                                                        domain_description=domain_description)},
                {"role": "user", "content": self.prompt_user().format(description=metrics_description, 
                                                                    metrics=metrics_results)}
            ],
            temperature=0.3
        )
        
        print(completion.choices[0].message.content)
    
